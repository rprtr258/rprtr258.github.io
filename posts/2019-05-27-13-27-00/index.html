<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>О чистом рандоме | rprtr258</title>
<meta name=keywords content>
<meta name=description content="В перерывах между сохранениями артов с аниме девками
Однажды в пятницу на презентациях проектов, преподаватель во время презентации одного из проектов по machine learning высказался по поводу модели рандомного выбора. Решалась задача бинарной классификации то есть разделении инпута на две категории: хорошие данные или плохие данные. Так вот, когда были представлены замеры разных моделей, одной из них была модель подбрасывания монетки и определение результата просто из рандома. Эта модель показала результат чуть больше 0.">
<meta name=author content>
<link rel=canonical href=https://rprtr258.github.io/posts/2019-05-27-13-27-00/>
<link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://rprtr258.github.io/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://rprtr258.github.io/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://rprtr258.github.io/favicon-32x32.png>
<link rel=apple-touch-icon href=https://rprtr258.github.io/apple-touch-icon.png>
<link rel=mask-icon href=https://rprtr258.github.io/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><style>.main{max-width:calc(var(--main-width) + var(--gap) * 14)!important}article.first-entry{justify-content:inherit;min-height:auto}</style>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css integrity=sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0 crossorigin=anonymous>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js integrity=sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4 crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:'$$',right:'$$',display:!0},{left:'$',right:'$',display:!1},{left:'\\(',right:'\\)',display:!1},{left:'\\[',right:'\\]',display:!0}],throwOnError:!1})})</script>
<meta property="og:title" content="О чистом рандоме">
<meta property="og:description" content="В перерывах между сохранениями артов с аниме девками
Однажды в пятницу на презентациях проектов, преподаватель во время презентации одного из проектов по machine learning высказался по поводу модели рандомного выбора. Решалась задача бинарной классификации то есть разделении инпута на две категории: хорошие данные или плохие данные. Так вот, когда были представлены замеры разных моделей, одной из них была модель подбрасывания монетки и определение результата просто из рандома. Эта модель показала результат чуть больше 0.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://rprtr258.github.io/posts/2019-05-27-13-27-00/">
<meta property="og:image" content="https://rprtr258.github.io/img/vk/qg_ASWrYv44.jpg"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2019-05-27T13:27:00+03:00">
<meta property="article:modified_time" content="2019-05-27T13:27:00+03:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://rprtr258.github.io/img/vk/qg_ASWrYv44.jpg">
<meta name=twitter:title content="О чистом рандоме">
<meta name=twitter:description content="В перерывах между сохранениями артов с аниме девками
Однажды в пятницу на презентациях проектов, преподаватель во время презентации одного из проектов по machine learning высказался по поводу модели рандомного выбора. Решалась задача бинарной классификации то есть разделении инпута на две категории: хорошие данные или плохие данные. Так вот, когда были представлены замеры разных моделей, одной из них была модель подбрасывания монетки и определение результата просто из рандома. Эта модель показала результат чуть больше 0.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://rprtr258.github.io/posts/"},{"@type":"ListItem","position":2,"name":"О чистом рандоме","item":"https://rprtr258.github.io/posts/2019-05-27-13-27-00/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"О чистом рандоме","name":"О чистом рандоме","description":"В перерывах между сохранениями артов с аниме девками\nОднажды в пятницу на презентациях проектов, преподаватель во время презентации одного из проектов по machine learning высказался по поводу модели рандомного выбора. Решалась задача бинарной классификации то есть разделении инпута на две категории: хорошие данные или плохие данные. Так вот, когда были представлены замеры разных моделей, одной из них была модель подбрасывания монетки и определение результата просто из рандома. Эта модель показала результат чуть больше 0.","keywords":[],"articleBody":"В перерывах между сохранениями артов с аниме девками\nОднажды в пятницу на презентациях проектов, преподаватель во время презентации одного из проектов по machine learning высказался по поводу модели рандомного выбора. Решалась задача бинарной классификации то есть разделении инпута на две категории: хорошие данные или плохие данные. Так вот, когда были представлены замеры разных моделей, одной из них была модель подбрасывания монетки и определение результата просто из рандома. Эта модель показала результат чуть больше 0.5, что и возмутило преподавателя. Как он заявил, если монетка выдает хоть чуть чуть больше 0.5, то можно ее забустить и получить хорошую модель. Не задаваясь вопросом почему эта модель вообще была рассмотрена, попробуем разобраться так ли это.\nВо-первых, лично я не понимаю претензий по этому поводу, потому что рандом на то и рандом что может выдавать результаты немного отклоняющиеся от теоретических данных. То есть моя гипотеза в том, что при увеличении количества прогонов рандомной модели, ее усредненные результаты будут стремиться к 0.5. Проверять эту гипотезу мы не будем, так как это просто одна из интерпретаций вероятности и стремиться она может очень и очень долго. Рассмотрим лучше вторую часть утверждения: монетку, которая предсказывает с шансом чуть лучше, чем 0.5, можно забустить и получить хорошую модель. Видимо предполагается, что монетка всегда будет говорить верный ответ с этим самым шансом чуть больше 0.5, что скорее всего неверно, но мы примем это как данность.\nИтак сформулируем задачу: есть модель предсказывающая верный ответ с шансом 0.51 (те же расчеты можно провести с любой вероятностью меньше), нужно ее каким-то образом забустить так, чтобы получить «хорошую» модель, например, с шансом угадывания правильного ответа не менее 0.99 (опять таки его можно увеличить). Гуглинг по слову бустинга выдает какие-то алгоритмы в частности AdaBoost, но мне было лень читать тем более на википедии самого описания алгоритма я не нашел, а в кратком описании не разобрался так как не очень разбираюсь в терминах machine learning. Зато в гугл картинках нашлась такая схема: первая картинка по запросу machine learning boosting\nТак как мне интереснее по таким схемам додумывать алгоритм, чем читать его описание, которое тем более подразумевает обучение моделей, которого у нас нет, я решил разработать забущеную модель на основе следующего алгоритма:\n Возьмем очень много монеток и подбросим их для данного инпута На основе большинства монеток выдадим результат  Как видно на картинке используется именно такой алгоритм: выделяются синим только те зоны, за которые проголосовали не менее двух из трех первых моделей.\nИтак возьмем например 195 (совершенно случайное число) монеток и опробируем вышеописанный алгоритм на 1000 случайных данных:\none_layer: 0.61909090909090913612544682109728455543518066406250\nТакой шанс угадывания выдает новая мета-модель (весь код будет в конце статьи, так что вы можете проверить результаты сами). Это конечно не желаемые 0.99, но уже значительно лучше. Дальше я подумал, что теперь имея модель выдающую 0.61, можно забустить и ее ровно тем же самым образом. Действительно, возьмем 109 (тоже совершенно случайное число) новых «мета»-моделей и применим к ним тот же алгоритм и прогоним их тоже на 1000 данных (больше ideone не успевал):\ntwo_layer: 0.99090909090909096157417934591649100184440612792969\nВау, действительно получилось. Теперь можно разобраться почему так получилось и привести PoC код (хотя я сам как раз делал сначала расчеты а потом запустил модели для эксперименты).\nДопустим исходная модель давала вероятность $p$ выдать правильный ответ. Тогда проведя эксперименты по описанной выше схеме с нечетным (чтобы точно определить, что один из результатов превалирует) количеством исходных моделей, получим, что вероятность модели из n монеток имеет шанс угадать ответ:\n$$ \\sum\\limits_{k=\\frac{n+1}{2}}^n {n\\choose k}p^k(1-p)^{n-k} $$\nТак как сложно оценить эту сумму, посчитаем ее на ЭВМ при p = 0.51 при различных n (тут я бы мог вставить график зависимости суммы от n, но мне лень):\n   $n$ value     $187$ $0.60791510268042203701810421989648602902889251708984$   $189$ $0.60847479697657635977492418533074669539928436279297$   $191$ $0.60903132281386229696096279440098442137241363525391$   $193$ $0.60958472862817358883802398850093595683574676513672$   $195$ $0.61013506161391062310173083460540510714054107666016$   $197$ $0.61068236776822715228263405151665210723876953125000$   $199$ $0.61122669193325396275184857586282305419445037841797$   $201$ $0.61176807783643771809778399983770214021205902099609$   $203$ $0.61230656812907802155621084239101037383079528808594$   $205$ $0.61284220442316794663639711870928294956684112548828$    Видим, что эта сумма растет медленно, но превышает 0.6 уже на 195 монетках. Окей, как и описывалось возьмем эту модель и посчитаем ту же сумму уже при p = 0.61:\n   $n$ value     $93$ $0.98437112503143087138823830173350870609283447265625$   $95$ $0.98524806965791367208140627553802914917469024658203$   $97$ $0.98607387745086494401647314589354209601879119873047$   $99$ $0.98685169738443523357318554189987480640411376953125$   $101$ $0.98758446909873343066976758564123883843421936035156$   $103$ $0.98827493833300716907785954390419647097587585449219$   $105$ $0.98892567106284867683996253617806360125541687011719$   $107$ $0.98953906646756828457967003487283363938331604003906$   $109$ $0.99011736883963319399981628521345555782318115234375$   $111$ $0.99066267853564293766055470769060775637626647949219$    Тут уже рост гораздо быстрее и также мы наконец видим желаемые 0.99 на 109 моделях.\nДальше хочется проверить эту модель с 195 монетками на первом «уровне» и с 109 «метамоделями» на втором «уровне», посчитать ее фактический результат, матожидание и дисперсию среди 1000 прогонов (мало так как мы имеем 109*195 = 21 255 работающих монеток на один запуск модели):\n         expected $0.98999999999999999111821580299874767661094665527344$   variance $0.00989999999999987938259504716143055702559649944305$    Бабах, модель работает очень неплохо, по сравнению с начальной монеткой.\nКакой же вывод из всего этого можно сделать? Во-первых забустить слабый алгоритм machine learning несложно, и тогда появляется вопрос о применимости техник бустинга и вопрос зачем выбирать модели и архитектуры, если их всегда можно забустить. Вряд ли быстродействие является значимым препятствием для такой схемы. Далее, если исходить из предположения, что монетка, угадавшая на нескольких прогонах 0.51 тестовых данных, далее всегда будет угадывать не хуже, то действительно пробрасывание монетку кучу раз это эффективная модель machine learning. Даже если она дает ответы реже, чем 0.5, то ее результат можно инвертировать(так как у нас задача бинарной классификации) и получим монетку, с шансом больше чем 0.5. То есть если мы отрицаем, что подбрасывание монетки это достойное решение задачи machine learning, то либо неверно предположение: монетки иногда угадывают чаще, чем 0.5, а иногда реже, либо же мы ошибаемся. Значит при верности предположения (которое я думаю, что неверно) преподаватель был прав и модель монетки должна давать ИДЕАЛЬНЫЕ 0.5 на любых данных.\nКод calcs.py — вычисление суммы, поменяйте p для расчетов для другой исходной модели\nimport math def nCr(n,r): f = math.factorial return f(n) // f(r) // f(n-r) p = 0.51 for nn in range(1000): s = 0 n = 2 * nn + 1 for k in range(nn + 1, n + 1): s += (p ** k) * ((1 - p) ** (n - k)) * nCr(n, k) print(\"%d: %.50f\" % (n, s)) models.py — описание и тестирование моделей в виде лямбд\nfrom random import random def get_majority(s): s = list(s) return 0 if s.count(0)  s.count(1) else 1 def test_model(model): x = (0 if random()  0.5 else 1) prediction = model(x) return (prediction == x) def test_average(model, tests_count): s = 0 for _ in range(tests_count): s += test_model(model) return s / tests_count # model slightly better than just flip coin, accuracy: 0.51 nice_roll_model = lambda x: (x if random()  0.51 else 1 - x) # one layer model with expected accuracy 0.61 one_layer_model = lambda x: get_majority(nice_roll_model(x) for _ in range(195)) # two layer model with expected accuracy 0.99 two_layer_model = lambda x: get_majority(one_layer_model(x) for _ in range(109)) # expected: 0.51 res = test_average(nice_roll_model, 1000) print(\"nice_roll: %.50f\" % (res)) # expected: 0.61 res = test_average(one_layer_model, 1000) print(\"one_layer: %.50f\" % (res)) # expected: 0.99 res = test_average(two_layer_model, 1000) print(\"two_layer: %.50f\" % (res)) RUNS = 1000 results = [] for _ in range(RUNS): res = test_model(two_layer_model) results.append(res) expected = sum(results) / RUNS variance = sum((x - expected) ** 2 for x in results) / RUNS print(\"expected: %.50f\" % (expected)) print(\"variance: %.50f\" % (variance)) ","wordCount":"1153","inLanguage":"en","image":"https://rprtr258.github.io/img/vk/qg_ASWrYv44.jpg","datePublished":"2019-05-27T13:27:00+03:00","dateModified":"2019-05-27T13:27:00+03:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://rprtr258.github.io/posts/2019-05-27-13-27-00/"},"publisher":{"@type":"Organization","name":"rprtr258","logo":{"@type":"ImageObject","url":"https://rprtr258.github.io/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://rprtr258.github.io/ accesskey=h title="rprtr258 (Alt + H)">rprtr258</a>
<div class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</div>
</div>
<ul id=menu>
<li>
<a href=https://rprtr258.github.io/watch_list/ title="Watch list">
<span>Watch list</span>
</a>
</li>
<li>
<a href=https://rprtr258.github.io/cv/ title=CV>
<span>CV</span>
</a>
</li>
<li>
<a href=https://rprtr258.github.io/menhera/ title="Menhera chan">
<span>Menhera chan</span>
</a>
</li>
<li>
<a href=https://rprtr258.github.io/mmheroes/ title=MMHeroes>
<span>MMHeroes</span>
</a>
</li>
<li>
<a href=https://rprtr258.github.io/utils/ title="Utils (18+)">
<span>Utils (18+)</span>
</a>
</li>
<li>
<a href=https://rprtr258.github.io/memes/ title=Memes>
<span>Memes</span>
</a>
</li>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<div class=breadcrumbs><a href=https://rprtr258.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://rprtr258.github.io/posts/>Posts</a></div>
<h1 class=post-title>
О чистом рандоме
</h1>
<div class=post-meta><span title="2019-05-27 13:27:00 +0300 +0300">May 27, 2019</span>
</div>
</header>
<figure class=entry-cover><img loading=lazy src=https://rprtr258.github.io/img/vk/qg_ASWrYv44.jpg alt>
</figure>
<div class=post-content><p>В перерывах между сохранениями артов с аниме девками</p>
<p>Однажды в пятницу на презентациях проектов, преподаватель во время презентации одного из проектов по machine learning высказался по поводу модели рандомного выбора. Решалась задача бинарной классификации то есть разделении инпута на две категории: хорошие данные или плохие данные. Так вот, когда были представлены замеры разных моделей, одной из них была модель подбрасывания монетки и определение результата просто из рандома. Эта модель показала результат чуть больше 0.5, что и возмутило преподавателя. Как он заявил, если монетка выдает хоть чуть чуть больше 0.5, то можно ее забустить и получить хорошую модель. Не задаваясь вопросом почему эта модель вообще была рассмотрена, попробуем разобраться так ли это.</p>
<p>Во-первых, лично я не понимаю претензий по этому поводу, потому что рандом на то и рандом что может выдавать результаты немного отклоняющиеся от теоретических данных. То есть моя гипотеза в том, что при увеличении количества прогонов рандомной модели, ее усредненные результаты будут стремиться к 0.5. Проверять эту гипотезу мы не будем, так как это просто одна из интерпретаций вероятности и стремиться она может очень и очень долго. Рассмотрим лучше вторую часть утверждения: монетку, которая предсказывает с шансом чуть лучше, чем 0.5, можно забустить и получить хорошую модель. Видимо предполагается, что монетка всегда будет говорить верный ответ с этим самым шансом чуть больше 0.5, что скорее всего неверно, но мы примем это как данность.</p>
<p>Итак сформулируем задачу: есть модель предсказывающая верный ответ с шансом 0.51 (те же расчеты можно провести с любой вероятностью меньше), нужно ее каким-то образом забустить так, чтобы получить «хорошую» модель, например, с шансом угадывания правильного ответа не менее 0.99 (опять таки его можно увеличить). Гуглинг по слову бустинга выдает какие-то алгоритмы в частности AdaBoost, но мне было лень читать тем более на википедии самого описания алгоритма я не нашел, а в кратком описании не разобрался так как не очень разбираюсь в терминах machine learning. Зато в гугл картинках нашлась такая схема:
первая картинка по запросу machine learning boosting</p>
<p><img loading=lazy src=/img/vk/EM5p--ykyD0.jpg alt>
</p>
<p>Так как мне интереснее по таким схемам додумывать алгоритм, чем читать его описание, которое тем более подразумевает обучение моделей, которого у нас нет, я решил разработать забущеную модель на основе следующего алгоритма:</p>
<ol>
<li>Возьмем очень много монеток и подбросим их для данного инпута</li>
<li>На основе большинства монеток выдадим результат</li>
</ol>
<p>Как видно на картинке используется именно такой алгоритм: выделяются синим только те зоны, за которые проголосовали не менее двух из трех первых моделей.</p>
<p>Итак возьмем например 195 (совершенно случайное число) монеток и опробируем вышеописанный алгоритм на 1000 случайных данных:</p>
<p>one_layer: 0.61909090909090913612544682109728455543518066406250</p>
<p>Такой шанс угадывания выдает новая мета-модель (весь код будет в конце статьи, так что вы можете проверить результаты сами). Это конечно не желаемые 0.99, но уже значительно лучше. Дальше я подумал, что теперь имея модель выдающую 0.61, можно забустить и ее ровно тем же самым образом. Действительно, возьмем 109 (тоже совершенно случайное число) новых «мета»-моделей и применим к ним тот же алгоритм и прогоним их тоже на 1000 данных (больше ideone не успевал):</p>
<p>two_layer: 0.99090909090909096157417934591649100184440612792969</p>
<p>Вау, действительно получилось. Теперь можно разобраться почему так получилось и привести PoC код (хотя я сам как раз делал сначала расчеты а потом запустил модели для эксперименты).</p>
<p>Допустим исходная модель давала вероятность $p$ выдать правильный ответ. Тогда проведя эксперименты по описанной выше схеме с нечетным (чтобы точно определить, что один из результатов превалирует) количеством исходных моделей, получим, что вероятность модели из n монеток имеет шанс угадать ответ:</p>
<p>$$
\sum\limits_{k=\frac{n+1}{2}}^n {n\choose k}p^k(1-p)^{n-k}
$$</p>
<p>Так как сложно оценить эту сумму, посчитаем ее на ЭВМ при p = 0.51 при различных n (тут я бы мог вставить график зависимости суммы от n, но мне лень):</p>
<table>
<thead>
<tr>
<th>$n$</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>$187$</td>
<td>$0.60791510268042203701810421989648602902889251708984$</td>
</tr>
<tr>
<td>$189$</td>
<td>$0.60847479697657635977492418533074669539928436279297$</td>
</tr>
<tr>
<td>$191$</td>
<td>$0.60903132281386229696096279440098442137241363525391$</td>
</tr>
<tr>
<td>$193$</td>
<td>$0.60958472862817358883802398850093595683574676513672$</td>
</tr>
<tr>
<td>$195$</td>
<td>$0.61013506161391062310173083460540510714054107666016$</td>
</tr>
<tr>
<td>$197$</td>
<td>$0.61068236776822715228263405151665210723876953125000$</td>
</tr>
<tr>
<td>$199$</td>
<td>$0.61122669193325396275184857586282305419445037841797$</td>
</tr>
<tr>
<td>$201$</td>
<td>$0.61176807783643771809778399983770214021205902099609$</td>
</tr>
<tr>
<td>$203$</td>
<td>$0.61230656812907802155621084239101037383079528808594$</td>
</tr>
<tr>
<td>$205$</td>
<td>$0.61284220442316794663639711870928294956684112548828$</td>
</tr>
</tbody>
</table>
<p>Видим, что эта сумма растет медленно, но превышает 0.6 уже на 195 монетках. Окей, как и описывалось возьмем эту модель и посчитаем ту же сумму уже при p = 0.61:</p>
<table>
<thead>
<tr>
<th>$n$</th>
<th>value</th>
</tr>
</thead>
<tbody>
<tr>
<td>$93$</td>
<td>$0.98437112503143087138823830173350870609283447265625$</td>
</tr>
<tr>
<td>$95$</td>
<td>$0.98524806965791367208140627553802914917469024658203$</td>
</tr>
<tr>
<td>$97$</td>
<td>$0.98607387745086494401647314589354209601879119873047$</td>
</tr>
<tr>
<td>$99$</td>
<td>$0.98685169738443523357318554189987480640411376953125$</td>
</tr>
<tr>
<td>$101$</td>
<td>$0.98758446909873343066976758564123883843421936035156$</td>
</tr>
<tr>
<td>$103$</td>
<td>$0.98827493833300716907785954390419647097587585449219$</td>
</tr>
<tr>
<td>$105$</td>
<td>$0.98892567106284867683996253617806360125541687011719$</td>
</tr>
<tr>
<td>$107$</td>
<td>$0.98953906646756828457967003487283363938331604003906$</td>
</tr>
<tr>
<td>$109$</td>
<td>$0.99011736883963319399981628521345555782318115234375$</td>
</tr>
<tr>
<td>$111$</td>
<td>$0.99066267853564293766055470769060775637626647949219$</td>
</tr>
</tbody>
</table>
<p>Тут уже рост гораздо быстрее и также мы наконец видим желаемые 0.99 на 109 моделях.</p>
<p>Дальше хочется проверить эту модель с 195 монетками на первом «уровне» и с 109 «метамоделями» на втором «уровне», посчитать ее фактический результат, матожидание и дисперсию среди 1000 прогонов (мало так как мы имеем 109*195 = 21 255 работающих монеток на один запуск модели):</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>expected</td>
<td>$0.98999999999999999111821580299874767661094665527344$</td>
</tr>
<tr>
<td>variance</td>
<td>$0.00989999999999987938259504716143055702559649944305$</td>
</tr>
</tbody>
</table>
<p>Бабах, модель работает очень неплохо, по сравнению с начальной монеткой.</p>
<p>Какой же вывод из всего этого можно сделать? Во-первых забустить слабый алгоритм machine learning несложно, и тогда появляется вопрос о применимости техник бустинга и вопрос зачем выбирать модели и архитектуры, если их всегда можно забустить. Вряд ли быстродействие является значимым препятствием для такой схемы. Далее, если исходить из предположения, что монетка, угадавшая на нескольких прогонах 0.51 тестовых данных, далее всегда будет угадывать не хуже, то действительно пробрасывание монетку кучу раз это эффективная модель machine learning. Даже если она дает ответы реже, чем 0.5, то ее результат можно инвертировать(так как у нас задача бинарной классификации) и получим монетку, с шансом больше чем 0.5. То есть если мы отрицаем, что подбрасывание монетки это достойное решение задачи machine learning, то либо неверно предположение: монетки иногда угадывают чаще, чем 0.5, а иногда реже, либо же мы ошибаемся. Значит при верности предположения (которое я думаю, что неверно) преподаватель был прав и модель монетки должна давать ИДЕАЛЬНЫЕ 0.5 на любых данных.</p>
<h2 id=код>Код<a hidden class=anchor aria-hidden=true href=#код>#</a></h2>
<p>calcs.py — вычисление суммы, поменяйте p для расчетов для другой исходной модели</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> math
 
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>nCr</span>(n,r):
    f <span style=color:#f92672>=</span> math<span style=color:#f92672>.</span>factorial
    <span style=color:#66d9ef>return</span> f(n) <span style=color:#f92672>//</span> f(r) <span style=color:#f92672>//</span> f(n<span style=color:#f92672>-</span>r)
 
p <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.51</span>
<span style=color:#66d9ef>for</span> nn <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>1000</span>):
 s <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
 n <span style=color:#f92672>=</span> <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> nn <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>
 <span style=color:#66d9ef>for</span> k <span style=color:#f92672>in</span> range(nn <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, n <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>):
  s <span style=color:#f92672>+=</span> (p <span style=color:#f92672>**</span> k) <span style=color:#f92672>*</span> ((<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> p) <span style=color:#f92672>**</span> (n <span style=color:#f92672>-</span> k)) <span style=color:#f92672>*</span> nCr(n, k)
 print(<span style=color:#e6db74>&#34;</span><span style=color:#e6db74>%d</span><span style=color:#e6db74>: </span><span style=color:#e6db74>%.50f</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> (n, s))  
</code></pre></div><p>models.py — описание и тестирование моделей в виде лямбд</p>
<div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> random <span style=color:#f92672>import</span> random
 
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_majority</span>(s):
	s <span style=color:#f92672>=</span> list(s)
	<span style=color:#66d9ef>return</span> <span style=color:#ae81ff>0</span> <span style=color:#66d9ef>if</span> s<span style=color:#f92672>.</span>count(<span style=color:#ae81ff>0</span>) <span style=color:#f92672>&gt;</span> s<span style=color:#f92672>.</span>count(<span style=color:#ae81ff>1</span>) <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>1</span>
 
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_model</span>(model):
  x <span style=color:#f92672>=</span> (<span style=color:#ae81ff>0</span> <span style=color:#66d9ef>if</span> random() <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>0.5</span> <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>1</span>)
  prediction <span style=color:#f92672>=</span> model(x)
  <span style=color:#66d9ef>return</span> (prediction <span style=color:#f92672>==</span> x)

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_average</span>(model, tests_count):
  s <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
  <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(tests_count):
    s <span style=color:#f92672>+=</span> test_model(model)
  <span style=color:#66d9ef>return</span> s <span style=color:#f92672>/</span> tests_count
 
<span style=color:#75715e># model slightly better than just flip coin, accuracy: 0.51</span>
nice_roll_model <span style=color:#f92672>=</span> <span style=color:#66d9ef>lambda</span> x: (x <span style=color:#66d9ef>if</span> random() <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>0.51</span> <span style=color:#66d9ef>else</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> x)
<span style=color:#75715e># one layer model with expected accuracy 0.61</span>
one_layer_model <span style=color:#f92672>=</span> <span style=color:#66d9ef>lambda</span> x: get_majority(nice_roll_model(x) <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>195</span>))
<span style=color:#75715e># two layer model with expected accuracy 0.99</span>
two_layer_model <span style=color:#f92672>=</span> <span style=color:#66d9ef>lambda</span> x: get_majority(one_layer_model(x) <span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>109</span>))
 
<span style=color:#75715e># expected: 0.51</span>
res <span style=color:#f92672>=</span> test_average(nice_roll_model, <span style=color:#ae81ff>1000</span>)
print(<span style=color:#e6db74>&#34;nice_roll: </span><span style=color:#e6db74>%.50f</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> (res))
<span style=color:#75715e># expected: 0.61</span>
res <span style=color:#f92672>=</span> test_average(one_layer_model, <span style=color:#ae81ff>1000</span>)
print(<span style=color:#e6db74>&#34;one_layer: </span><span style=color:#e6db74>%.50f</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> (res))
<span style=color:#75715e># expected: 0.99</span>
res <span style=color:#f92672>=</span> test_average(two_layer_model, <span style=color:#ae81ff>1000</span>)
print(<span style=color:#e6db74>&#34;two_layer: </span><span style=color:#e6db74>%.50f</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> (res))

RUNS <span style=color:#f92672>=</span> <span style=color:#ae81ff>1000</span>
results <span style=color:#f92672>=</span> []
<span style=color:#66d9ef>for</span> _ <span style=color:#f92672>in</span> range(RUNS):
  res <span style=color:#f92672>=</span> test_model(two_layer_model)
  results<span style=color:#f92672>.</span>append(res)
expected <span style=color:#f92672>=</span> sum(results) <span style=color:#f92672>/</span> RUNS
variance <span style=color:#f92672>=</span> sum((x <span style=color:#f92672>-</span> expected) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span> <span style=color:#66d9ef>for</span> x <span style=color:#f92672>in</span> results) <span style=color:#f92672>/</span> RUNS
print(<span style=color:#e6db74>&#34;expected: </span><span style=color:#e6db74>%.50f</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> (expected))
print(<span style=color:#e6db74>&#34;variance: </span><span style=color:#e6db74>%.50f</span><span style=color:#e6db74>&#34;</span> <span style=color:#f92672>%</span> (variance))
</code></pre></div>
</div>
<footer class=post-footer>
<ul class=post-tags>
</ul>
<nav class=paginav>
<a class=prev href=https://rprtr258.github.io/posts/2019-10-24-11-21-53/>
<span class=title>« Prev</span>
<br>
<span>О беспроигрышности</span>
</a>
<a class=next href=https://rprtr258.github.io/posts/2019-05-02-19-16-00/>
<span class=title>Next »</span>
<br>
<span>roflanPominki</span>
</a>
</nav>
</footer>
</article>
</main>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>