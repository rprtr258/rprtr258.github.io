<h3><a name="monte-carlo-tree" href="https://habr.com/post/330092/">Поиск по дереву методом Монте-Карло и крестики-нолики</a></h3>
Узлы дерева - состояния игры и пара: кол-во выигранных партий из этой позиции(или суммарный выигрыш), кол-во всех партий из этой позиции.
Обучение происходит одновременно с игрой следующим образом:
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/MCTS_%28English%29.svg/808px-MCTS_%28English%29.svg.png">
Происходит игра как обычно, среди всех ходов дерево выбирает ход с наибольшим отношением победы/кол-во игр(Selection), если нет ходов с положительным количеством побед, то выбирается вершина, которая еще не изучена(Expansion). В конце игры дереву сообщается его выигрыш (например 1 при выигрыше и 0 при проигрыше, Simulation) и с возвратом назад обновляются вершины, которые были пройдены(Backpropagation).
<h3 name="shen-games">А. Шень Игры и стратегии с точки зрения математики|Краткое описание конечных игр и примеры задач</h3>
2. Несколько простых примеров
Простые примеры игр, примеры решения части из них.
3. Классификация позиций
Разделение позиций на выигрышные и проигрышные(для текущего игрока) в играх без ничьих. Конечные позиции определены, для остальных позиций:
позиция выигрышная, если есть ход в проигрышную позицию, иначе если все ходы ведут в выигрышные позиции, то наша позиция проигрышная.
4. Игра Ним
Разбор игры Ним, доказательство решения.
5. Симметрия
Применение симметрии для нахождения оптимальных стратегий в играх, разбор примеров.
6. Выигрышные стратегии: разное
Разбор примеров игр в которых доказывается, что определенная стратегия выигрышная.
7. Изоморфизм игр
Примеры изоморфных игр.
8. Игры с многими исходами
Добавление выигрышей для первого и второго игрока, нулевой выигрыш соответствует ничьей.
9. Формальные определения и доказательства
Формальное определение игры, доказательство существования цены игры и стратегий на нее.
10. Теоремы существования
Примеры доказательств существования оптимальной стратегии без ее построения.
11. Игры Шпрага-Гранди
Разбор и доказательство теории Шпрага-Гранди, оценка для суммы игр.
12. Программирование игр
Кратко о программировании игровых программ.
13. Бесконечные игры
Примеры бесконечных игр.
14. Игры с неполной информацией
Примеры игр с неполной информацией, отсылка на теорию игр.
<h3><a name="ai-technics-review" href="https://habr.com/post/420219/">Обзор техник реализации игрового ИИ</a></h3>
<b>Дерево принятия решений</b>
<img src="https://habrastorage.org/getpro/habr/post_images/34e/4a2/17e/34e4a217e703a6af9b51b5cfbec7370f.png">
Используется для более структурированной записи условий для поведения, может быть представлено в виде текста и следовательно конфигурироваться независимо от кода(в отличии от захардкодированных условий).
<b>Скриптинг</b>
<table><tbody>
    <tr>
        <td><b>Номер узла</b></td>
        <td><b>Решение (или «конец»)</b></td>
        <td><b>Решение</b></td>
        <td><b>Действие</b></td>
    </tr>
        <tr>
        <td>1</td>
        <td><b>ball.position.x &lt; paddle.position.x</b></td>
        <td>Да? Проверить узел 2</td>
        <td>Нет? Проверить узел 3</td>
    </tr>
        <tr>
        <td>2</td>
        <td><i>Конец</i></td>
        <td colspan="2">Двигать ракетку влево</td>
    </tr>
    <tr>
        <td>3</td>
        <td><b>ball.position.x &gt; paddle.position.x</b></td>
        <td>Да? Проверить узел 4</td>
        <td>Нет? Проверить узел 5</td>
    </tr>
    <tr>
        <td>4</td>
        <td><i>Конец</i></td>
        <td colspan="2">Двигать ракетку вправо</td>
    </tr>
    <tr>
        <td>5</td>
        <td><i>Конец</i></td>
        <td colspan="2">Ничего не делать</td>
    </tr>
</tbody></table>
Можно написать часть дерева решений на скриптовом языке, тем самым передав больше управления дизайнеру ии. Кроме того вообще все поведение может быть переписано на скриптовом языке, например, Lua или Angelscript.
<b>Реакция на события</b>
Все поведение определяется реакцией на какие-либо события. Однако в этом случае нет возможности отслеживать состояние агента.
<b>Конечные автоматы</b>
<img src="https://habrastorage.org/getpro/habr/post_images/ee0/a7b/262/ee0a7b2621204b58f17703a71b78ed67.png">
Набор состояний агента с переходами между ними как реакции на события.
<b>Иерархические конечные автоматы</b>
<img src="https://habrastorage.org/getpro/habr/post_images/240/7a0/21f/2407a021fd5e60c214d79069b86148d4.png">
Для сокращения одинаковых переходов и связи близких состояний(в данном случае небоевых состояний) можно их выделить в отдельный автомат и переходить в него как единое состояние из внешнего состояния.
<b>Дерево поведения</b>
<img src="https://habrastorage.org/getpro/habr/post_images/9b9/0f2/d18/9b90f2d18ce7b78b8a9a0673b8cde3d2.png">
Для обьединения переходов и более логичного описания переходов можно использовать дерево с узлами "декораторами"(Sequence - выполнять потомки по очереди, Selector - выполнить первый потомок слева направо который возможно выполнить). В этом случае явно переходы между состояниями не прописываются и тем самым если были одинаковые переходы в автомате, то в этом дереве условие на него будет в одном месте. Как только происходит какое-либо событие дерево проходится заново для определения нового состояния. Также можно добавить узлы для циклического повтора событий чтобы после небоевых действий не обходить дерево заново:
<img src="https://habrastorage.org/getpro/habr/post_images/187/487/d73/187487d733f1db9e07920b0475894bb4.png">
<b>Системы на основе полезности</b>
<table>
<tbody>
<tr>
<td><b>Действие</b><br>
<br>
</td>
<td><b>Вычисление полезности</b><br>
<br>
</td>
</tr>
<tr>
<td><i>Поиск помощи</i><br>
<br>
</td>
<td>Если враг видим и враг силён, а здоровья мало, то возвращаем 100, в противном случае возвращаем 0<br>
<br>
</td>
</tr>
<tr>
<td><i>Бегство</i><br>
<br>
</td>
<td>Если враг видим и здоровья мало, то возвращаем 90, иначе возвращаем 0<br>
</td>
</tr>
<tr>
<td><i>Нападение</i><br>
<br>
</td>
<td>Если враг видим, возвращаем 80<br>
<br>
</td>
</tr>
<tr>
<td><i>Ожидание</i><br>
<br>
</td>
<td>Если находимся в состоянии ожидания и уже ждём 10 секунд, возвращаем 0, в противном случае 50<br>
<br>
</td>
</tr>
<tr>
<td><i>Патрулирование</i><br>
<br>
</td>
<td>Если находимся в конце маршрута патрулирования, возвращаем 0, в противном случае 50</td>
</tr>
</tbody>
</table>
Вместо прописывания состояний в какой-то четкой структуре можно высчитывать для каждого варианта ответного действия количество очков полезности и на основе этих очков определять самое полезное действие. Также эту систему можно встравать в дерево решений или автомат частично для более гибкого поведения.
<b>Движение и навигация</b>
Варианты алгоритмов для движения агента по карте.
<b>Steering</b>
Выделяются некоторые виды движения агента(красться, бежать, приближаться) которые высчитывают вектор ускорения который прибавляется к текущему вектору скорости по которому и двигается агент.
<b>Поиск путей</b>
Карту можно разделить на клетки и искать путь с помощью bfs или A*, который обследует меньше клеток.
<img src="https://habrastorage.org/getpro/habr/post_images/f12/08e/15f/f1208e15fc83ffa2b7ac3eca652854fc.gif">
bfs<br>
<img src="https://habrastorage.org/getpro/habr/post_images/128/406/091/128406091bee8168b7b0e398386797da.gif">
A*<br>
<b>Движение без сетки</b>
Т.к. сетка может содержать слишком много клеток для просмотра можно заменить сетку на граф, заменив клетки контрольными точками и отобрав из них вручную самые важные.
<img src="https://habrastorage.org/getpro/habr/post_images/0f9/a09/70d/0f9a0970dfadfd31260ae81c93d8792b.png">
Но так как выбирать их вручную может быть долго или затруднительно(в частности на трехмерных картах) есть алгоритмы для того чтобы автоматически разделять карту на области и ассоциировать их с вершинами графа, как например navmesh.
<img src="https://habrastorage.org/getpro/habr/post_images/860/051/69e/86005169e23bd5d646664aeecf688b3a.png">
<b>Планирование</b>
Выше были техники для реализации "мгновенного" поведения, которые не дают агенту "глобальной" задачи. Для этого нужно использовать планирование задач.
<b>Простой «планировщик»</b>
Можно перебирать дерево из возможных действий(приводится пример из короткого хода в mtg) и, оценив результат после каждого варианта действий, реализовать его.
<b>Улучшенное планирование</b>
Однако это дерево может быть слишком большим для обхода. Для решения этой проблемы есть несколько способов:
<b>Backwards chaining</b>
Начиная с результата, который желательнее всего получить, можно перебрать их все, пока не найдем вариант, который можно реализовать. Например поставить "мат" в шахматах или убить противника в mtg.
<b>Поиск по первому наилучшему совпадению</b>
Вместо обхода всего дерева можно смотреть насколько хорош каждый из переходов и рассматривать дальше только несколько лучших.
<b>Поиск по дереву Монте-Карло</b>
<i>также см. <a href="https://rprtr258.github.io/book_descriptions.html#monte-carlo-tree">выше</a></i>
На каждом шагу выбирается случайное действие в дереве вариантов и в конце набор действий оценивается. Прогоняя это множество раз можно получить хорошие оценки вариантов действий.
<b>Планирования действий на основе целей</b>
То же планирование на основе результата, но тут результат это цель, которая фиксируется и от него строится план событий. Например, если целью было «убить игрока» и игрок находится в укрытии, то план может быть таким: «Выкурить игрока гранатой» → «Вытащить оружие» → «Атаковать». Также можно задавать несколько целей и задавать им приоритеты.
<b>Обучение и адаптация</b>
Хотя рассматриваемые варианты ии были фиксированы, можно использовать информацию, получаемую во время игры и на основе ее менять свое поведение, то есть "обучаться".
<b>Статистика и вероятности</b>
Сначала можно узнать насколько мы можем предсказать действия игрока на основе записей по ходу игры. Например, записывая время первой атаки игрока, можно экстраполировать это значение и узнать будет ли игрок атаковать рано или будет ждать, и на основе этого строить свою стратегию. Также можно используя Naive Bayes Classifier(наивный байесовский классификатор) отслеживая все полезные параметры(создаваемые вражеские юниты, используемые заклинания или исследуемые технологии) можно классифицировать стратегию игрока или какие-то другие аспекты(война/мир, стратегия раша/стратегия защиты и т.д.). С помощью этих техник можно обучить ии до выпуска игры во время плейтестинга, чтобы он был более подготовлен. Однако может быть две крайности: ии может либо слишком сложен для большинства игроков либо же слишком не приспособленным к новым противникам и потому легким.
<b>Простая адаптация на основе весов</b>
Вместо выбора между дискретными наборами стратегий в результате обучения можно выбирать непрерывные значения параметров(например приоритеты изучения/построения юнитов/зданий) и на основе действий игрока и успешности исхода игры поднимать или опускать приоритет действия.
<b>Марковские модели</b>
Среди действий игрока можно выделить конечный набор который можно отслеживать в каждой игре, например в какую комнату игрок предпочитает идти и после какой:
<table>
<tbody>
<tr>
<td><b>Первая комната, в которой замечен игрок</b></td>
<td><b>Всего наблюдений</b></td>
<td><b>Следующая комната</b></td>
<td><b>Сколько раз замечен</b><br>
<br>
</td>
<td><b>Процент</b><br>
<br>
</td>
</tr>
<tr>
<td rowspan="3">Красная<br>
<br>
</td>
<td rowspan="3">10<br>
<br>
</td>
<td>Красная<br>
<br>
</td>
<td>2<br>
<br>
</td>
<td>20%<br>
<br>
</td>
</tr>
<tr>
<td>Зелёная<br>
<br>
</td>
<td>7<br>
<br>
</td>
<td>70%<br>
<br>
</td>
</tr>
<tr>
<td>Синяя<br>
<br>
</td>
<td>1<br>
<br>
</td>
<td>10%<br>
<br>
</td>
</tr>
<tr>
<td rowspan="3">Зелёная<br>
<br>
</td>
<td rowspan="3">10<br>
<br>
</td>
<td>Красная<br>
<br>
</td>
<td>3<br>
<br>
</td>
<td>30%<br>
<br>
</td>
</tr>
<tr>
<td>Зелёная<br>
<br>
</td>
<td>5<br>
<br>
</td>
<td>50%<br>
<br>
</td>
</tr>
<tr>
<td>Синяя<br>
<br>
</td>
<td>2<br>
<br>
</td>
<td>20%<br>
<br>
</td>
</tr>
<tr>
<td rowspan="3">Синяя<br>
<br>
</td>
<td rowspan="3">8<br>
<br>
</td>
<td>Красная<br>
<br>
</td>
<td>6<br>
<br>
</td>
<td>75%<br>
<br>
</td>
</tr>
<tr>
<td>Зелёная<br>
</td>
<td>2<br>
<br>
</td>
<td>25%<br>
<br>
</td>
</tr>
<tr>
<td>Синяя<br>
<br>
</td>
<td>0<br>
<br>
</td>
<td>0%</td>
</tr>
</tbody>
</table>
На основе этих наблюдений можно построить цепь Маркова:
<img src="https://habrastorage.org/getpro/habr/post_images/e43/53b/691/e4353b691807e7476a2255f91dc2f248.png">
На основе этого можно предсказывать с каким шансом на разных этапах в какой комнате будет игрок, если мы знаем, что сейчас он в Зеленой комнате:
<table>
<tbody>
<tr>
<td><b>Наблюдение 1</b><br>
<br>
</td>
<td><b>Гипотетическое наблюдение 2</b><br>
<br>
</td>
<td><b>Вероятность в процентах</b><br>
<br>
</td>
<td><b>Гипотетическое наблюдение 3</b><br>
<br>
</td>
<td><b>Вероятность в процентах</b><br>
<br>
</td>
<td><b>Накапливаемая вероятность</b><br>
<br>
</td>
</tr>
<tr>
<td rowspan="10">Зелёная<br>
</td>
<td rowspan="3">Красная<br>
<br>
</td>
<td rowspan="3">30%<br>
<br>
</td>
<td>Красная<br>
<br>
</td>
<td>20%<br>
<br>
</td>
<td>6%<br>
<br>
</td>
</tr>
<tr>
<td><b>Зелёная</b><br>
<br>
</td>
<td>70%<br>
<br>
</td>
<td><b>21%</b><br>
<br>
</td>
</tr>
<tr>
<td>Синяя<br>
<br>
</td>
<td>10%<br>
<br>
</td>
<td>3%<br>
<br>
</td>
</tr>
<tr>
<td rowspan="3">Зелёная<br>
</td>
<td rowspan="3">50%<br>
<br>
</td>
<td>Красная<br>
<br>
</td>
<td>30%<br>
<br>
</td>
<td>15%<br>
<br>
</td>
</tr>
<tr>
<td><b>Зелёная</b><br>
<br>
</td>
<td>50%<br>
<br>
</td>
<td><b>25%</b><br>
<br>
</td>
</tr>
<tr>
<td>Синяя<br>
<br>
</td>
<td>20%<br>
<br>
</td>
<td>10%<br>
<br>
</td>
</tr>
<tr>
<td rowspan="3">Синяя<br>
<br>
</td>
<td rowspan="3">20%<br>
<br>
</td>
<td>Красная<br>
<br>
</td>
<td>75%<br>
<br>
</td>
<td>15%<br>
<br>
</td>
</tr>
<tr>
<td><b>Зелёная</b><br>
<br>
</td>
<td>25%<br>
<br>
</td>
<td><b>5%</b><br>
<br>
</td>
</tr>
<tr>
<td>Синяя<br>
<br>
</td>
<td>0%<br>
<br>
</td>
<td>0%<br>
<br>
</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td><i>Всего:</i><br>
<br>
</td>
<td>100%</td>
</tr>
</tbody>
</table>
В итоге шанс, что игрок через 2 шага будет в Зеленой комнате 51%, 36% на Красную комнату. Шанс, что он придет в Зеленую комнату из Зеленой(то есть останется там один ход) 25%, а что придет из Красной 21%.
<b>N-граммы</b>
Также можно исследовать события на основе их последовательности, например для отслеживания комбо в файтинге и готовности к соответственной защите. Тогда можно отслеживать например 3 последних действия, следя за применение комбо удар ногой-ногой-рукой:<br>
Н - удар ногой, Р - удар рукой<br>
<table><tbody>
<tr>
    <td><b>Ввод</b><br>
    <br>
    </td>
    <td><b>Уже имеющаяся последовательность ввода</b><br>
    <br>
    </td>
    <td><b>Новая память ввода</b><br>
    <br>
    </td>
</tr>
<tr>
    <td> Н<br>
    <br>
    </td>
    <td> Н<br>
    <br>
    </td>
    <td><i>нет</i><br>
    <br>
    </td>
</tr>
<tr>
    <td> Р<br>
    <br>
    </td>
    <td> Н,  Р<br>
    <br>
    </td>
    <td><i>нет</i><br>
    <br>
    </td>
</tr>
<tr>
    <td> Н<br>
    <br>
    </td>
    <td> Н,  Р,  Н<br>
    <br>
    </td>
    <td> Н,  Р,  Н<br>
    </td>
</tr>
<tr>
    <td> Н<br>
    <br>
    </td>
    <td> Н,  Р,  Н,  Н<br>
    <br>
    </td>
    <td> Р,  Н,  Н<br>
    <br>
    </td>
</tr>
<tr>
    <td><b> Р</b><br>
    <br>
    </td>
    <td><b> Н,  Р,  Н,  Н,  Р</b><br>
    <br>
    </td>
    <td><b> Н,  Н,  Р</b><br>
    <br>
    </td>
</tr>
<tr>
    <td>Блок<br>
    <br>
    </td>
    <td> Н,  Р,  Н,  Н,  Р, блок<br>
    <br>
    </td>
    <td> Н,  Р, блок<br>
    <br>
    </td>
</tr>
<tr>
    <td> Н<br>
    <br>
    </td>
    <td> Н,  Р,  Н,  Н,  Р, блок,  Н<br>
    <br>
    </td>
    <td> Р, блок,  Н<br>
    <br>
    </td>
</tr>
<tr>
    <td> Н<br>
    <br>
    </td>
    <td> Н,  Р,  Н,  Н,  Р, блок,  Н,  Н<br>
    <br>
    </td>
    <td>Блок,  Н,  Н<br>
    <br>
    </td>
</tr>
<tr>
    <td><b> Р</b><br>
    <br>
    </td>
    <td><b> Н,  Р,  Н,  Н,  Р, блок,  Н,  Н,  Р</b><br>
    <br>
    </td>
    <td><b> Н,  Н,  Р</b></td>
</tr>
</tbody></table>
Затем по записанным данным по N последним действиям(здесь 3) можно предсказывать следующее действие и, например, если это вероятнее всего комбо, то отвечать защитой.
<b>Представление знания</b>
Также ии может потребоваться знание обо всем мире, которое можно учитывать для дальнейших действий.
<b>Тэги/метки</b>
Для каждого обьекта в мире можно добавлять метку(например COVER для укрытий) по которым можно искать нужный в текущий момент обьект, не перебирая все вообще обьекты мира.
<b>Умные объекты</b>
Однако для тэгов может быть сложная структура, например, места для тренировки имеют тэг TRAINING, но для разных классов могут понадобится разные тэги ARCHER-TRAINING, WIZARD-TRAINING etc. Однако если у нас будут места для смешанных тренировок, то придется создавать метки, обьединяющие две существующие. Тогда можно для одного обьекта хранить несколько тегов и тем самым один и тот же обьект будет рассмотрен и как один тип и как другой. Другой прием заключается в том, что вместо тега можно идентифицировать обьект непосредственно по влиянию(например +1 к скиллу мечника) и тем самым поиск осуществлять по наличию требуемых параметров.
<table>
<tbody>
<tr>
<td><br>
<br>
</td>
<td><b>Выполняемая анимация</b><br>
<br>
</td>
<td><b>Результат для пользователя</b><br>
<br>
</td>
</tr>
<tr>
<td><i>Стрельбище</i><br>
<br>
</td>
<td>Shoot-Arrow<br>
<br>
</td>
<td>+10 к навыку Archery<br>
<br>
</td>
</tr>
<tr>
<td><i>Школа магии</i><br>
<br>
</td>
<td>Sword-Duel<br>
<br>
</td>
<td>+10 к навыку Swords<br>
<br>
</td>
</tr>
<tr>
<td rowspan="2"><i>Школа Робина Гуда</i><br>
<br>
</td>
<td>Shoot-Arrow<br>
<br>
</td>
<td>+15 к навыку Archery<br>
<br>
</td>
</tr>
<tr>
<td>Sword-Duel<br>
<br>
</td>
<td>+8 к навыку Swords<br>
<br>
</td>
</tr>
<tr>
<td rowspan="2"><i>Академия Гэндальфа</i><br>
<br>
</td>
<td>Sword-Duel<br>
<br>
</td>
<td>+5 к навыку Swords<br>
<br>
</td>
</tr>
<tr>
<td>Cast-Spell<br>
<br>
</td>
<td>+10 к навыку Magic</td>
</tr>
</tbody>
</table>
<b>Кривые реакций</b>
Также некоторые параметры мира можно измерить как непрерывные значения(уровень здоровья или расстояние до противника). Тогда т.к. поведение агента зависит от этих параметров, то нельзя их просто, например, взять и сложить т.к. это даст неверную оценку ситуации. Вместо этого можно каждый из этих параметров привести к фиксированному интервалу(здесь [0,1]) и затем уже оценивать например безопасность как сумму. Но одни параметры могут быть важнее чем другие и по разному переводиться(например персонаж в относительной безопасности если у него больше 30% здоровья, но в опасности если меньше 20%) и тем самым эти данные могут регулироваться гейм-дизайнерами с помощью кривых реакций(здесь линейная для здоровья и нелинейная для расстояния до противника(если он далеко то не важно насколько сильно)):
<img src="https://habrastorage.org/getpro/habr/post_images/e3f/65f/9a9/e3f65f9a90b2557c5408e529c477fb12.png">
<img src="https://habrastorage.org/getpro/habr/post_images/9b7/8bf/be7/9b78bfbe758bf8407a3abe44b430e7a5.png">
<b>Blackboards</b>
Все агенты могут записывать данные о мире на общую "доску" из которой все могут запросить ее, не опрашивая постоянно мир. Также неважную информацию можно удалять по прошествии времени для чего можно использовать с заметками запись момента времени, когда она была сделана.
<b>Карты влияния (Influence Maps)</b>
Если мы можем оценить вред/пользу от обьектов на карте, то можно сложить их, получая карту влияния, которой пользоваться для более умного продвижения по карте. Например, если у игрока за стеной стоит 3 катапульты и нам нужно атаковать стену, то выбрать место для атаки можно по следующей карте:
<img src="https://habrastorage.org/getpro/habr/post_images/1aa/da0/6d7/1aada06d7ea16ef8e2e6bca315c196c5.png">
Также дружественные обьекты могут давать "минус" опасность, нивелируя влияние противников:
<img src="https://habrastorage.org/getpro/habr/post_images/726/4db/e7b/7264dbe7b1834f3602b36deddc723163.png">

<h3><a name="pissed-off" href="https://www.perlmonks.org/?node_id=450922">pissed off about functional programming</a></h3>
<h1>Myth #1 - Functional programming is Lambda Calculus</h1>
Это истина настолько же, насколько истинно, что императивное программирование это последовательное оперирование числами. Однако это заканчивается как только мы, например, оперируем слишком большими числами. Так же и в функциональном программировании появляются бесконечные списки, которые не могут быть точно представлены внутри компьютера. Это однако обходится техникой ленивого вычисления элементов списка по порядку. Поэтому и функциональное программирование не является точным лямбда исчислением.
<h1>Myth #2 - Functional programming is 'different from' imperative programming</h1>
Все тьюринг-полные языки эквивалентны, то есть функциональное программирование эквивалентно императивному. (Да это противоречит первому пункту)
<h1>Myth #3 - Functional programming is referentially transparent</h1>
Возможность заменять переменные на их значение нарушается в функциональном программировании даже без использования присваиваний, а именно в различных областях видимости.
<h1>Myth #4 - Functional programming doesn't support variable assignment</h1>
Присваивание можно заменить на бесконечный список значений переменной на определенных шагах, который из-за ленивости вычислений все-таки можно менять. Также вместо этих значений можно хранить операции над значением, которое было на предыдущем шаге.

